{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "bucket = os.getenv('BUCKET_NAME')\n",
    "endpoint_name = os.getenv('ENDPOINT_NAME')\n",
    "sagemaker_session = sagemaker.Session(default_bucket=bucket)\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "entry_point = 'sklearn_featureizer.py'\n",
    "source_dir = 'pipeline'\n",
    "\n",
    "s3_output_key_prefix = \"training_output\"\n",
    "model_output_path = 's3://{}/{}/{}'.format(bucket, s3_output_key_prefix, 'sgd') # rename based on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need to change this\n",
    "train_input = 's3://beularnotebookstack-beularsagemakerapibucket1198e-xck265jh9uop/training_output/train/train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminate model training after 48 hours\n",
    "train_max_run = 48 * 60 * 60\n",
    "\n",
    "grid_search = SKLearn(\n",
    "    framework_version='0.23-1',\n",
    "    source_dir=source_dir,\n",
    "    entry_point=entry_point,\n",
    "    role=role,\n",
    "    train_instance_type=\"ml.c5.18xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    output_path=model_output_path,\n",
    "    train_max_run=train_max_run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this will take awhile.\n",
    "grid_search.fit({'train': train_input}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the Model\n",
    "We now have a fitted model (i.e. the best estimator from the Grid Search) in our s3 bucket. We can now deploy this model behind a single endpoint. When this is done, you'll be able to see this endpoint under Endpoints in the SageMaker console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "model = grid_search.create_model(role=role)\n",
    "model.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.c5.xlarge',\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request inferences from the endpoint\n",
    "With our model deployed behind a REST API, we'll now make some requests to it in order to get inferences from our validation set. We can then use these inferences to see how well the trained model performs on out-of-sample data.\n",
    "\n",
    "Note that we need to make our request with the payload in text/csv format, since that is what our script currently supports (see input_fn() in our entrypoint file). If other formats need to be supported, this would have to be added to that input_fn() function. Note, however, that we set the accept to application/json to get our output, i.e. the inferences, that way. We do this because our ouput_fn() function returns JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "df = pd.read_csv(train_input)\n",
    "\n",
    "df.columns = ['Clause ID', 'Clause Text', 'Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import f1_score, brier_score_loss\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=csv_serializer,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictor.predict(\"This is a test\")\n",
    "prediction = json.loads(pred)\n",
    "\n",
    "import base64\n",
    "base64.b64decode(prediction['instances'][0]['expl'].encode('utf-8')).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will delete the endpoint to clean up\n",
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
