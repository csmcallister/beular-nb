{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "bucket = os.getenv('BUCKET_NAME')\n",
    "endpoint_name = os.getenv('ENDPOINT_NAME')\n",
    "sagemaker_session = sagemaker.Session(default_bucket=bucket)\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a SageMaker Scikit estimator\n",
    "Here we create an instance of a sagemaker.sklearn.estimator.sklearn estimator. The constructor accepts several constructor arguments:\n",
    "\n",
    "- source_dir: Path (absolute or relative) to the directory with our custom model training source code.\n",
    "- entry_point: The path to the Python script SageMaker runs for training and prediction within source_dir.\n",
    "- role: Role ARN, which is provided by get_execution_role()\n",
    "- train_instance_type (optional): The type of SageMaker instances for training. Note: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types. Also, note that you may need to request an EC2 quota increase for these ml ec2 instance types.\n",
    "- sagemaker_session (optional): The session used to train on Sagemaker, as returned by sagemaker.Session().\n",
    "- output_path (optional): s3 location where you want the training result (model artifacts and optional output files) saved. If not specified, results are stored to a default bucket. If the bucket with the specific name does not exist, the estimator creates the bucket during execution of the fit() method.\n",
    "- train_max_run (optional): Timeout in seconds for training (default: 24 60 60). After this amount of time Amazon SageMaker terminates the job regardless of its current status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "entry_point = 'sklearn_featureizer.py'\n",
    "source_dir = 'pipeline'\n",
    "\n",
    "s3_output_key_prefix = \"training_output\"\n",
    "model_output_path = 's3://{}/{}/{}'.format(bucket, s3_output_key_prefix, 'model')\n",
    "\n",
    "# terminate model training after 48 hours\n",
    "train_max_run = 48 * 60 * 60\n",
    "\n",
    "grid_search = SKLearn(\n",
    "    framework_version='0.23-1',\n",
    "    source_dir=source_dir,\n",
    "    entry_point=entry_point,\n",
    "    role=role,\n",
    "    train_instance_type=\"ml.c5.4xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    output_path=model_output_path,\n",
    "    train_max_run=train_max_run\n",
    ")\n",
    "\n",
    "train_input = f's3://{bucket}/AI_ML_Challenge_Training_Data_Set_1_v1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this will take awhile.\n",
    "grid_search.fit({'train': train_input}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the Model\n",
    "We now have a fitted model (i.e. the best estimator from the Grid Search) in our s3 bucket. We can now deploy this model behind a single endpoint. When this is done, you'll be able to see this endpoint under Endpoints in the SageMaker console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "model = grid_search.create_model(role=role)\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.c5.xlarge',\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request inferences from the endpoint\n",
    "With our model deployed behind a REST API, we'll now make some requests to it in order to get inferences from our validation set. We can then use these inferences to see how well the trained model performs on out-of-sample data.\n",
    "\n",
    "Note that we need to make our request with the payload in text/csv format, since that is what our script currently supports (see input_fn() in our entrypoint file). If other formats need to be supported, this would have to be added to that input_fn() function. Note, however, that we set the accept to application/json to get our output, i.e. the inferences, that way. We do this because our ouput_fn() function returns JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "df = pd.read_csv(train_input)\n",
    "\n",
    "df.columns = ['Clause ID', 'Clause Text', 'Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import f1_score, brier_score_loss\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=csv_serializer,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_JSON\n",
    ")\n",
    "\n",
    "\n",
    "preds = []\n",
    "samples_to_drop = []\n",
    "clauses = df['Clause Text'].iloc[:10].tolist()\n",
    "for clause in clauses:\n",
    "    try:\n",
    "        pred = predictor.predict(clause)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(clause)\n",
    "    preds.append(pred)\n",
    "\n",
    "y_pred = []\n",
    "pred_probs = []\n",
    "for i, p in enumerate(preds):\n",
    "    result = json.loads(p)\n",
    "    pred = result.get(\"instances\")[0].get('prediction')\n",
    "    pred_prob = result.get(\"instances\")[0].get('decision boundary')\n",
    "    pred_probs.append(pred_prob)\n",
    "    y_pred.append(pred)\n",
    "\n",
    "y_true = df['Classification'].iloc[:10].tolist()\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "bs = brier_score_loss(y_true, pred_probs)\n",
    "print(f\"f1: {f1}\\nbs: {bs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will delete the endpoint to clean up\n",
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}